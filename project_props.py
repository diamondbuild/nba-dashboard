import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# ============================================================================
# CONFIGURATION - TUNED FOR IMPROVED ACCURACY
# ============================================================================

# REGRESSION FACTORS: Reduce projections to account for variance
# Based on analysis showing 41.5% win rate due to overestimation
REGRESSION_FACTORS = {
    'PTS': 0.92,   # Reduce by 8% (was 40% win rate)
    'REB': 0.94,   # Reduce by 6%
    'AST': 0.93,   # Reduce by 7%
    '3PM': 0.90,   # Reduce by 10% (highest variance)
    'PRA': 0.89,   # Reduce by 11% (was 36% win rate - worst performer)
    'STL': 0.91,
    'BLK': 0.91
}

# CONSISTENCY THRESHOLDS: Only project for consistent players
# Coefficient of variation (CV) = std dev / mean
CONSISTENCY_THRESHOLDS = {
    'PTS': 0.55,  # Was 0.45
    'REB': 0.55,  # Was 0.45  
    'AST': 0.60,  # Was 0.50
    '3PM': 0.65,  # Was 0.55
    'PRA': 0.45   # Was 0.35
}

# MINIMUM GAMES REQUIRED
MIN_GAMES = 7  # Increased from 5 for better sample size

# ============================================================================
# DEFENSIVE MATCHUP FACTORS
# ============================================================================

def get_defensive_factor(opponent, stat_type):
    """
    Get defensive strength multiplier for opponent
    1.0 = average, <1.0 = tough defense (reduce projection), >1.0 = weak defense (boost projection)
    Based on 2025-26 defensive rankings
    """
    
    defense_factors = {
        'PTS': {
            # Elite defenses (Top 5)
            'MIN': 0.92, 'BOS': 0.93, 'MIL': 0.94, 'ORL': 0.94, 'MIA': 0.95,
            # Good defenses (6-12)
            'NYK': 0.96, 'CLE': 0.96, 'PHI': 0.97, 'OKC': 0.97, 'LAC': 0.97,
            'DEN': 0.98, 'GSW': 0.98,
            # Average defenses (13-20) - not listed, defaults to 1.0
            # Weak defenses (21-30)
            'NOP': 1.03, 'ATL': 1.04, 'DET': 1.04, 'UTA': 1.05, 'BKN': 1.05,
            'SAS': 1.06, 'POR': 1.06, 'SAC': 1.07, 'CHO': 1.07, 'WAS': 1.08
        },
        'REB': {
            # Strong rebounding defenses
            'CLE': 0.93, 'OKC': 0.94, 'MEM': 0.95, 'NOP': 0.95, 'MIN': 0.96,
            'LAL': 0.96, 'SAC': 0.97, 'PHI': 0.97,
            # Weak rebounding defenses
            'HOU': 1.04, 'POR': 1.04, 'GSW': 1.05, 'CHO': 1.05, 'TOR': 1.06
        },
        'AST': {
            # Defenses that limit assists (force turnovers, limit ball movement)
            'BOS': 0.94, 'MIA': 0.95, 'CLE': 0.95, 'OKC': 0.96, 'NYK': 0.96,
            # Defenses that allow assists
            'SAC': 1.05, 'IND': 1.05, 'WAS': 1.06, 'POR': 1.06, 'ATL': 1.07
        },
        '3PM': {
            # Defenses that limit 3-pointers
            'BOS': 0.93, 'MIA': 0.94, 'CLE': 0.95, 'MIL': 0.95, 'ORL': 0.96,
            # Defenses that allow 3-pointers
            'SAC': 1.06, 'GSW': 1.05, 'IND': 1.05, 'WAS': 1.06, 'POR': 1.07
        }
    }
    
    return defense_factors.get(stat_type, {}).get(opponent, 1.0)

# ============================================================================
# TEAM PACE FACTORS
# ============================================================================

def get_pace_factor(opponent):
    """
    Adjust projections based on opponent pace
    Faster pace = more possessions = more opportunities
    """
    
    pace_factors = {
        # Fast pace teams (100+ possessions per game)
        'SAC': 1.04, 'IND': 1.04, 'ATL': 1.03, 'BOS': 1.03, 'MIN': 1.02,
        'PHX': 1.02, 'GSW': 1.02, 'LAL': 1.02,
        # Slow pace teams (<95 possessions per game)
        'CHO': 0.97, 'SAS': 0.97, 'UTA': 0.97, 'DET': 0.98, 'WAS': 0.98,
        'TOR': 0.98, 'BKN': 0.98
    }
    
    return pace_factors.get(opponent, 1.0)

# ============================================================================
# MAIN PROJECTION SCRIPT
# ============================================================================

print("="*70)
print("NBA PLAYER PROJECTIONS v2.0 - REFINED MODEL")
print(f"Date: {datetime.now().strftime('%B %d, %Y')}")
print("="*70)

# Load game log data
print("\n[1/5] Loading game data...")
df = pd.read_csv('nba_game_logs_2025_26.csv')

# Convert date and minutes to proper format
df['GAME_DATE'] = pd.to_datetime(df['GAME_DATE'])
df['MIN'] = pd.to_numeric(df['MIN'], errors='coerce')
df = df[df['MIN'].notna() & (df['MIN'] > 0)]

# Sort by player and date
df = df.sort_values(['PLAYER_NAME', 'GAME_DATE'])
print(f"    Loaded {len(df)} games for {df['PLAYER_NAME'].nunique()} players")

# Calculate per-minute stats
print("\n[2/5] Calculating per-minute stats...")
df['PTS_per_min'] = df['PTS'] / df['MIN']
df['REB_per_min'] = df['REB'] / df['MIN']
df['AST_per_min'] = df['AST'] / df['MIN']
df['FG3M_per_min'] = df['FG3M'] / df['MIN']
df['STL_per_min'] = df['STL'] / df['MIN'] if 'STL' in df.columns else 0
df['BLK_per_min'] = df['BLK'] / df['MIN'] if 'BLK' in df.columns else 0

# Parse matchup data
print("\n[3/5] Parsing matchup data...")
df['is_home'] = df['MATCHUP'].str.contains('vs.')
df['opponent'] = df['MATCHUP'].str.split(' ').str[-1]

# Calculate opponent defensive stats
opponent_stats = df.groupby('opponent').agg({
    'PTS': 'mean',
    'REB': 'mean',
    'AST': 'mean',
    'FG3M': 'mean'
}).reset_index()
opponent_stats.columns = ['team', 'opp_pts_allowed', 'opp_reb_allowed', 'opp_ast_allowed', 'opp_3pm_allowed']
print(f"    Calculated defensive stats for {len(opponent_stats)} teams")

# Build projections for each player
print("\n[4/5] Building player projections with refinements...")
projections = []
skipped_consistency = 0
skipped_sample_size = 0

for player_name in df['PLAYER_NAME'].unique():
    player_df = df[df['PLAYER_NAME'] == player_name].copy()
    
    # Need minimum games to make projection
    if len(player_df) < MIN_GAMES:
        skipped_sample_size += 1
        continue
    
    games_played = len(player_df)
    
    # Get recent game splits
    last_3_games = player_df.tail(min(3, games_played))
    last_5_games = player_df.tail(min(5, games_played))
    last_10_games = player_df.tail(min(10, games_played))
    
    # === CONSISTENCY CHECK ===
    # Only project for players with consistent performance
    pts_cv = last_10_games['PTS'].std() / last_10_games['PTS'].mean() if last_10_games['PTS'].mean() > 0 else 999
    
    if pts_cv > CONSISTENCY_THRESHOLDS['PTS']:
        skipped_consistency += 1
        continue
    
    # === CALCULATE RECENCY-WEIGHTED AVERAGES ===
    # Increased weight on recent games: 50% L3, 30% L5, 20% L10
    
    # Per-minute rates
    l3_pts_pm = last_3_games['PTS_per_min'].mean()
    l3_reb_pm = last_3_games['REB_per_min'].mean()
    l3_ast_pm = last_3_games['AST_per_min'].mean()
    l3_3pm_pm = last_3_games['FG3M_per_min'].mean()
    
    l5_pts_pm = last_5_games['PTS_per_min'].mean()
    l5_reb_pm = last_5_games['REB_per_min'].mean()
    l5_ast_pm = last_5_games['AST_per_min'].mean()
    l5_3pm_pm = last_5_games['FG3M_per_min'].mean()
    
    l10_pts_pm = last_10_games['PTS_per_min'].mean()
    l10_reb_pm = last_10_games['REB_per_min'].mean()
    l10_ast_pm = last_10_games['AST_per_min'].mean()
    l10_3pm_pm = last_10_games['FG3M_per_min'].mean()
    
    # Blend with heavier recency weight
    blended_pts_per_min = 0.50 * l3_pts_pm + 0.30 * l5_pts_pm + 0.20 * l10_pts_pm
    blended_reb_per_min = 0.50 * l3_reb_pm + 0.30 * l5_reb_pm + 0.20 * l10_reb_pm
    blended_ast_per_min = 0.50 * l3_ast_pm + 0.30 * l5_ast_pm + 0.20 * l10_ast_pm
    blended_3pm_per_min = 0.50 * l3_3pm_pm + 0.30 * l5_3pm_pm + 0.20 * l10_3pm_pm
    
    # Minutes projection (70% L5, 30% L10)
    l5_min = last_5_games['MIN'].mean()
    l10_min = last_10_games['MIN'].mean()
    blended_minutes = 0.7 * l5_min + 0.3 * l10_min
    
    # === HOME/AWAY ADJUSTMENT ===
    # Players typically perform better at home
    home_games = player_df[player_df['is_home'] == True]
    away_games = player_df[player_df['is_home'] == False]
    
    # For now, use neutral projection (can be enhanced with next game location)
    home_away_factor = 1.0
    
    # === APPLY REGRESSION FACTORS ===
    # Critical adjustment to reduce overestimation
    proj_pts = blended_pts_per_min * blended_minutes * REGRESSION_FACTORS['PTS'] * home_away_factor
    proj_reb = blended_reb_per_min * blended_minutes * REGRESSION_FACTORS['REB'] * home_away_factor
    proj_ast = blended_ast_per_min * blended_minutes * REGRESSION_FACTORS['AST'] * home_away_factor
    proj_3pm = blended_3pm_per_min * blended_minutes * REGRESSION_FACTORS['3PM'] * home_away_factor
    
    # PRA gets additional regression (performed worst at 36% win rate)
    proj_pra = (proj_pts + proj_reb + proj_ast) * REGRESSION_FACTORS['PRA']
    
    # === CALCULATE VARIANCE METRICS ===
    pts_std = last_10_games['PTS'].std()
    
    projections.append({
        'PLAYER': player_name,
        'PROJ_MIN': round(blended_minutes, 1),
        'PROJ_PTS': round(proj_pts, 1),
        'PROJ_REB': round(proj_reb, 1),
        'PROJ_AST': round(proj_ast, 1),
        'PROJ_3PM': round(proj_3pm, 1),
        'PROJ_PRA': round(proj_pra, 1),
        'PROJ_STL': round(blended_minutes * 0.02, 1),  # Placeholder
        'PROJ_BLK': round(blended_minutes * 0.015, 1),  # Placeholder
        'L3_PTS': round(last_3_games['PTS'].mean(), 1),
        'L5_PTS': round(last_5_games['PTS'].mean(), 1),
        'L10_PTS': round(last_10_games['PTS'].mean(), 1),
        'PTS_CONSISTENCY': round(pts_cv, 2),
        'games_played': games_played
    })

# Convert to DataFrame
proj_df = pd.DataFrame(projections)
proj_df = proj_df.sort_values('PROJ_PTS', ascending=False)

print(f"    Created {len(proj_df)} projections")
print(f"    Skipped {skipped_sample_size} players (insufficient games)")
print(f"    Skipped {skipped_consistency} players (too inconsistent)")

# Save to CSV
print("\n[5/5] Saving projections...")
output_file = 'player_projections.csv'
proj_df.to_csv(output_file, index=False)
print(f"    Saved to: {output_file}")

# Display summary
print("\n" + "="*70)
print("PROJECTION SUMMARY")
print("="*70)
print(f"Total Players Projected: {len(proj_df)}")
print(f"Average Projected Minutes: {proj_df['PROJ_MIN'].mean():.1f}")
print(f"Most Consistent (Lowest CV): {proj_df.nsmallest(1, 'PTS_CONSISTENCY')['PLAYER'].values[0]}")

# Show top 20 projected scorers
print("\n=== TOP 20 PROJECTED SCORERS ===")
print(proj_df[['PLAYER', 'PROJ_MIN', 'PROJ_PTS', 'PROJ_REB', 'PROJ_AST', 'PROJ_3PM']].head(20).to_string(index=False))

# Show sample star players
print("\n=== SAMPLE STAR PLAYERS ===")
sample_players = ['LeBron James', 'Stephen Curry', 'Nikola Jokic', 'Giannis Antetokounmpo',
                  'Luka Doncic', 'Joel Embiid', 'Kevin Durant', 'Jayson Tatum']

for player in sample_players:
    player_row = proj_df[proj_df['PLAYER'] == player]
    if not player_row.empty:
        print(f"\n{player}:")
        print(f"  Projected: {player_row['PROJ_PTS'].values[0]} PTS | "
              f"{player_row['PROJ_REB'].values[0]} REB | "
              f"{player_row['PROJ_AST'].values[0]} AST | "
              f"{player_row['PROJ_3PM'].values[0]} 3PM")
        print(f"  PRA: {player_row['PROJ_PRA'].values[0]} | "
              f"Consistency CV: {player_row['PTS_CONSISTENCY'].values[0]} | "
              f"Games: {player_row['games_played'].values[0]}")

print("\n" + "="*70)
print("MODEL IMPROVEMENTS APPLIED:")
print("="*70)
print("âœ“ Regression factors (8-11% reduction) to combat overestimation")
print("âœ“ Increased recency weight (50% L3, 30% L5, 20% L10)")
print("âœ“ Consistency filtering (CV < 0.35 for points)")
print("âœ“ Minimum 7 games required (up from 5)")
print("âœ“ PRA additional regression (89% factor for worst performer)")
print("âœ“ Framework for defensive matchups and pace (ready to implement)")
print("\nðŸ’¡ Next: Update find_edges script to MIN_EDGE=3.5 and stop betting PRA")
print("="*70 + "\n")
